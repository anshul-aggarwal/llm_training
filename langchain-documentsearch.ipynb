{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdec41fb-c8f5-4b12-84e0-0502a3d20cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b8d133-7089-4e34-bc2e-6d76fbc64aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv() # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "openai.organization = os.getenv(\"OPENAI_ORGANIZATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1863db8-8c74-4708-95b0-a2770f39ebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import SKLearnVectorStore\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f9c968c-9a81-4e1f-a514-4525dede45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8aa4ee7-0431-4296-a8f7-092b59c640eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ansaggarwal\\repositories\\langchain\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b355f70f-2aeb-46a8-a34d-faa3143117a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_path = os.path.join(tempfile.gettempdir(), \"union.parquet\")\n",
    "\n",
    "vector_store = SKLearnVectorStore.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    persist_path=persist_path,  # persist_path and serializer are optional\n",
    "    serializer=\"parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0717073-4b7e-4ef5-b59a-3694654aeb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So here's the gradient descent algorithm. I'm going to choose some initial point. It could \n",
      "be vector of all zeros or some randomly chosen  point. Let's say we start from that point \n",
      "denoted by the star, by the cross, and now I wa nt you to imagine that this display actually \n",
      "shows a 3D landscape. Imagine you're all in a hi lly park or something, and this is the 3D \n",
      "shape of, like, a hill in some park.  \n",
      "So imagine you're actually standing physically at the position of that star, of that cross, \n",
      "and imagine you can stand on that hill, ri ght, and look all 360 degrees around you and \n",
      "ask, if I were to take a small step, what would allow me to go downhill the most? Okay, just imagine that this is physically a hill and you're standing there, and would look around \n",
      "ask, \"If I take a small step, what is the direc tion of steepest descent, that would take me \n",
      "downhill as quickly as possible?\"  \n",
      "So the gradient descent algorith m does exactly that. I'm going to take a small step in this \n",
      "direction of steepest des cent, or the direction that the gr adient turns out to be. And then \n",
      "you take a small step and you end up at a ne w point shown there, and it would keep \n",
      "going. You're now at a new point on this hi ll, and again you're going to look around you, \n",
      "look all 360 degrees around you, and ask, \"What is the direction that would take me \n",
      "downhill as quickly as possible?\"  \n",
      "And we want to go downhill as quickly as possible, because we want to find the \n",
      "minimum of J of theta. So you do that agai n. You can take another step, okay, and you \n",
      "sort of keep going until you end up at a loca l minimum of this function, J of theta. One \n",
      "property of gradient descent is  that where you end up – in this  case, we ended up at this \n",
      "point on the lower left hand corner of this plot.  \n",
      "But let's try running gradient descent again fr om a different position. So that was where I \n",
      "started gradient descent just now. Let's rer un gradient descent, but using a slightly \n",
      "different initial starting point, so a point sli ghtly further up and furthe r to the right. So it \n",
      "turns out if you run gradient de scent from that point, then if  you take a steepest descent \n",
      "direction again, that's your first step.  \n",
      "And if you keep going, it turns out that with a slightly different ini tial starting point, you \n",
      "can actually end up at a completely different lo cal optimum. Okay, so this is a property of \n",
      "gradient descent, and we'll come back to it in  a second. So be aware that gradient descent \n",
      "can sometimes depend on where you initialize yo ur parameters, theta zero and theta one.  \n",
      "Switch back to the chalkboard, please. Let' s go ahead and work out the math of the \n",
      "gradient descent algorithm. Then we'll come b ack and revisit this i ssue of local optimum. \n",
      "So here's the gradient descent algorithm.  \n",
      "We're going to take a repeatedly take a step  in the direction of steepest descent, and it \n",
      "turns out that you can write that as [inaudi ble], which is we're going to update the \n",
      "parameters theta as theta I minus the partial de rivative with respect to theta I, J of Theta. \n",
      "Okay, so this is how we're going to update the I parameter, theta I, how we're going to \n",
      "update Theta I on each iterati on of gradient descent.  \n"
     ]
    }
   ],
   "source": [
    "query = \"slope down\"\n",
    "results = vector_store.similarity_search(query)\n",
    "print(results[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90250f49-48aa-4197-b6e3-fff8a27c6431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='So here\\'s the gradient descent algorithm. I\\'m going to choose some initial point. It could \\nbe vector of all zeros or some randomly chosen  point. Let\\'s say we start from that point \\ndenoted by the star, by the cross, and now I wa nt you to imagine that this display actually \\nshows a 3D landscape. Imagine you\\'re all in a hi lly park or something, and this is the 3D \\nshape of, like, a hill in some park.  \\nSo imagine you\\'re actually standing physically at the position of that star, of that cross, \\nand imagine you can stand on that hill, ri ght, and look all 360 degrees around you and \\nask, if I were to take a small step, what would allow me to go downhill the most? Okay, just imagine that this is physically a hill and you\\'re standing there, and would look around \\nask, \"If I take a small step, what is the direc tion of steepest descent, that would take me \\ndownhill as quickly as possible?\"  \\nSo the gradient descent algorith m does exactly that. I\\'m going to take a small step in this \\ndirection of steepest des cent, or the direction that the gr adient turns out to be. And then \\nyou take a small step and you end up at a ne w point shown there, and it would keep \\ngoing. You\\'re now at a new point on this hi ll, and again you\\'re going to look around you, \\nlook all 360 degrees around you, and ask, \"What is the direction that would take me \\ndownhill as quickly as possible?\"  \\nAnd we want to go downhill as quickly as possible, because we want to find the \\nminimum of J of theta. So you do that agai n. You can take another step, okay, and you \\nsort of keep going until you end up at a loca l minimum of this function, J of theta. One \\nproperty of gradient descent is  that where you end up – in this  case, we ended up at this \\npoint on the lower left hand corner of this plot.  \\nBut let\\'s try running gradient descent again fr om a different position. So that was where I \\nstarted gradient descent just now. Let\\'s rer un gradient descent, but using a slightly \\ndifferent initial starting point, so a point sli ghtly further up and furthe r to the right. So it \\nturns out if you run gradient de scent from that point, then if  you take a steepest descent \\ndirection again, that\\'s your first step.  \\nAnd if you keep going, it turns out that with a slightly different ini tial starting point, you \\ncan actually end up at a completely different lo cal optimum. Okay, so this is a property of \\ngradient descent, and we\\'ll come back to it in  a second. So be aware that gradient descent \\ncan sometimes depend on where you initialize yo ur parameters, theta zero and theta one.  \\nSwitch back to the chalkboard, please. Let\\' s go ahead and work out the math of the \\ngradient descent algorithm. Then we\\'ll come b ack and revisit this i ssue of local optimum. \\nSo here\\'s the gradient descent algorithm.  \\nWe\\'re going to take a repeatedly take a step  in the direction of steepest descent, and it \\nturns out that you can write that as [inaudi ble], which is we\\'re going to update the \\nparameters theta as theta I minus the partial de rivative with respect to theta I, J of Theta. \\nOkay, so this is how we\\'re going to update the I parameter, theta I, how we\\'re going to \\nupdate Theta I on each iterati on of gradient descent.  ', metadata={'id': '6415ca28-30d4-4213-80d5-607864b12121', 'source': 'docs/cs229_lectures/MachineLearning-Lecture02.pdf', 'page': 6}),\n",
       " Document(page_content=\"gradient descent updates using my new paramete r vector that has already been modified \\nusing my first training exampl e. And then I keep going.  \\nMake sense? Yeah?  \\nStudent: So in each update of all the theta Is, you're only using –  \\nInstructor (Andrew Ng) :One training example.  \\nStudent: One training example.  \\nStudent: [Inaudible]?  \\nInstructor (Andrew Ng) :Let's see, it's definitely a [ina udible]. I believe this theory that \\nsort of supports that as we ll. Yeah, the theory that suppor ts that, the [inaudible] of \\ntheorem is, I don't remember.  \\nOkay, cool. So in what I've done so far, I've talked about an iterative algorithm for \\nperforming this minimization in terms of J of theta. And it tu rns out that there's another \\nway for this specific problem of least square s regression, of ordinary  least squares. It \\nturns out there's another way to perform this mi nimization of J of thet a that allows you to \\nsolve for the parameters theta in close fo rm, without needing to run an iterative \\nalgorithm.  \\nAnd I know some of you may have seen some of what I'm about to do before, in like an \\nundergraduate linear algebra co urse, and the way it's typica lly done requires [inaudible] \\nprojections, or taking lots of de rivatives and writing lots of algebra. What I'd like to do is \\nshow you a way to derive the closed form solutio n of theta in just a few lines of algebra.  \\nBut to do that, I'll need to in troduce a new notation for matrix  derivatives, and it turns out \\nthat, sort of, the nota tion I'm about to define here ju st in my own personal work has \\nturned out to be one of the mo st useful things that I actually  use all the time, to have a \\nnotation of how to take derivatives with resp ect to matrixes, so that you can solve for the \\nminimum of J of theta with, like, a few lines of algebra rather than  writing out pages and \\npages of matrices and derivatives.  \\nSo then we're going to define this new notati on first and then we'll go ahead and work out \\nthe minimization. Given a function J, since J is a function of a vector of parameters theta, \\nright, I'm going to define the deri vative of the gradient of J with respect to theta, as self of \\nvector. Okay, and so this is going to be an N plus one dimensional vector. Theta is an n \\nplus one dimensional vector with indices ranging from zero to N. And so I'm going to \\ndefine this derivative to be equal to that.  \\nOkay, and so we can actually rewrite the grad ient descent algorithm as follows. This is \\nbatch gradient descent, and we  write gradient descent as updating the para meter vector \", metadata={'id': '28d0ba51-d407-475f-bd5d-9e5dbd5c54b6', 'source': 'docs/cs229_lectures/MachineLearning-Lecture02.pdf', 'page': 12}),\n",
       " Document(page_content=\"And so if you – and this is a parameter of the algorithm that's often set by hand. If you \\nchoose alpha to be too small than your steep est descent algorithm will take very tiny \\nsteps and take a long time to converge. If alpha  is too large then the steepest descent may \\nactually end up overshooting the minimum, if  you're taking too a ggressive a step.  \\nYeah?  \\nStudent: [Inaudible].  \\nInstructor (Andrew Ng) :Say that again?  \\nStudent: Isn't there a one over two missing somewhere?  \\nInstructor (Andrew Ng) :Is there a one-half missing?  \\nStudent: I was [inaudible].  \\nInstructor (Andrew Ng) :Thanks. I do make lots of errors  in that. Any questions about \\nthis?  \\nAll right, so let me just wrap this property into an algorithm. So over there I derived the \\nalgorithm where you have just one training example, more generally for M training \\nexamples, gradient descent becomes the following. We're going to repeat until \\nconvergence the following step.  \\nOkay, theta I gets updated as theta I and I'm just writing out the appropriate equation for \\nM examples rather than one example. Theta I gets updated. Theta I minus alpha times the sum from I equals one to M. Okay, and I won't bother to show it, but you can go home \\nand sort of verify for yourself that this summation here, this is indeed the partial \\nderivative with respect to theta I of J of theta, where if you us e the original definition of J \\nof theta for when you have M training examples.  \\nOkay, so I'm just going to show – switch back to the laptop display. I'm going to show \\nyou what this looks like when you run the algor ithm. So it turns out that for the specific \\nproblem of linear regression, or ordinary release squares, which is what we're doing \\ntoday, the function J of theta actually does not lo ok like this nasty one that I'll show you \\njust now with a multiple local optima.  \\nIn particular, it turns out for ordi nary release squares, the functi on J of theta is – it's just a \\nquadratic function. And so we'll always ha ve a nice bow shape, like what you see up \\nhere, and only have one global mini mum with no other local optima.  \\nSo when you run gradient descent, here are actu ally the contours of the function J. So the \\ncontours of a bow shaped function like that  are going to be ellipses, and if you run \\ngradient descent on this algorithm, here's what  you might get. Let's see, so I initialize the \", metadata={'id': '8c33f121-c66c-41ba-8154-7f175ba42e6c', 'source': 'docs/cs229_lectures/MachineLearning-Lecture02.pdf', 'page': 8}),\n",
       " Document(page_content=\"at two different iterations and see if theta ha s changed a lot, and if  theta hasn't changed \\nmuch within two iterations, you may say it's sort of more or less converged.  \\nSomething that's done maybe slightly more often is look at the value of J of theta, and if J \\nof theta – if the quantity you're  trying to minimize is not changing much anymore, then \\nyou might be inclined to believe it's converged. So  these are sort of standard heuristics, or \\nstandard rules of thumb that are often used to  decide if gradient descent has converged.  \\nYeah?  \\nStudent: I may have missed something, but especial ly in [inaudible] descent. So one \\nfeature [inaudible] curve and can either go this  way or that way. But the math at incline \\n[inaudible] where that co mes in. When do you choose whether you go left, whether \\nyou're going this way or that way?  \\nInstructor (Andrew Ng) :I see. It just turns out that – so the question is, how is gradient \\ndescent looking 360 around you and choosing the direction of steepest descent. So it \\nactually turns out – I'm not su re I'll answer the second part , but it turns out that if you \\nstand on the hill and if you – it turns out th at when you compute the gradient of the \\nfunction, when you compute the derivative of the function, then it just turns out that that \\nis indeed the direction of steepest descent.  \\nBy the way, I just want to point out, you woul d never want to go in the opposite direction \\nbecause the opposite direction woul d actually be the direction of  steepest ascent, right. So \\nas it turns out – maybe the TAs can talk a bit more about this at th e section if there's \\ninterest. It turns out, when you take the de rivative of a function, the derivative of a \\nfunction sort of turns out to just give  you the direction of steepest descent.  \\nAnd so you don't explicitly look all 360 degr ees around you. You sort of just compute the \\nderivative and that turns out to  be the direction of steepest descent. Yeah, maybe the TAs \\ncan talk a bit more about this on Friday.  \\nOkay, let's see, so let me go ahead and give this algorithm a specific name. So this \\nalgorithm here is actually called batch gradient  descent, and the term batch isn't a great \\nterm, but the term batch refers to the fact that on every step of gradient descent you're \\ngoing to look at your entire training set. You're going to perform a sum over your M \\ntraining examples.  \\nSo [inaudible] descent often works very well.  I use it very often, and it turns out that \\nsometimes if you have a really, really large tr aining set, imagine that instead of having 47 \\nhouses from Portland, Oregon in our training set, if you had, say, the U.S. Census Database or something, with U.S. census size databases you often have hundreds of \\nthousands or millions of training examples.  \\nSo if M is a few million then if you're running batch rate and descent,  this means that to \\nperform every step of gradient descent you need  to perform a sum from J equals one to a \", metadata={'id': 'b8acac87-b84d-46cd-ab20-abca773f7a62', 'source': 'docs/cs229_lectures/MachineLearning-Lecture02.pdf', 'page': 10})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a3399-ebaf-4110-8b80-9aab209cdc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
