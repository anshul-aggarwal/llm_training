{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb9e9ee-7759-4e32-9e12-d044dd22d24a",
   "metadata": {},
   "source": [
    "# Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec41fb-c8f5-4b12-84e0-0502a3d20cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8d133-7089-4e34-bc2e-6d76fbc64aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv() # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "openai.organization = os.getenv(\"OPENAI_ORGANIZATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1863db8-8c74-4708-95b0-a2770f39ebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import SKLearnVectorStore\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c968c-9a81-4e1f-a514-4525dede45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents in langchain\n",
    "loader = DirectoryLoader('data/movies/', glob=\"*.txt\", show_progress=True)\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb7165-ecc1-4702-8861-e087d4a4b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 300,\n",
    "    chunk_overlap = 40,\n",
    "    length_function = len,\n",
    "    add_start_index = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aa4ee7-0431-4296-a8f7-092b59c640eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Embeddings in Langchain \n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b355f70f-2aeb-46a8-a34d-faa3143117a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_path = os.path.join(tempfile.gettempdir(), \"union.parquet\")\n",
    "\n",
    "vector_store = SKLearnVectorStore(\n",
    "    embedding=embeddings, \n",
    "    persist_path=persist_path, \n",
    "    serializer=\"parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d20b45-6b8d-4110-b406-04c6f9328f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = InMemoryStore()\n",
    "\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vector_store, \n",
    "    docstore=store, \n",
    "    child_splitter=text_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a919519b-8f7c-4b82-8231-bea0ae5cc4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.add_documents(docs, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c51188-8bc6-4ee5-9e89-bc487e20b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieved_docs = retriever.get_relevant_documents(\"<query>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ba3d7-f8ff-4892-98db-6e63f374daf1",
   "metadata": {},
   "source": [
    "## TO-DO: Create a document search system by combining the above elements\n",
    "\n",
    "Then, perform a search for the following:\n",
    "\n",
    "1. space\n",
    "2. what movie was based on magicians?\n",
    "3. i want to see a historical world war 2 movie\n",
    "\n",
    "\n",
    "And finally, summarise the movie result for the second query using the `GPT-3.5-turbo` model. Use langchain to create a summarisation pipeline. See the [\"Stuff\" chain here](https://python.langchain.com/docs/use_cases/summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e8d2e3-3c48-4732-a1b3-3d5086c32f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b304a7-800f-4700-839f-f4052ba66a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
